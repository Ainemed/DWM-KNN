{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Nearest Neighbor Classifiers\n",
    "\n",
    "**Nearest Neighbors**, can be used to determine the class label of the test instance. The justification for using nearest neighbors is best exemplified by the following saying: *“If it walks like a duck, quacks like a duck, and looks like a duck, then it’s probably a duck.”*\n",
    "\n",
    "A nearest neighbor classifier represents each example as a data point in a **d-dimensional** space, where $d$ is the number of attribute. \n",
    "\n",
    "Given a test instance, we compute its proximity to the training instances according to one of the proximity measures. \n",
    "The k-nearest neighbors of a given test instance $z$ refer to the k training examples that are closest to $z$.\n",
    "<space>\n",
    "<img src=\"knn-1.png\">\n",
    "<img src=\"knn-2.png\">"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdb86bd154f3e470"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Algorithm\n",
    "\n",
    " The algorithm computes the distance (or similarity) between each test instance $z = (x′,y′)$ and all the training examples $(x,y) ∈ D$ to determine its nearest neighbor list, $Dz$.\n",
    " \n",
    "Such computation can be costly if the number of training examples is large. However, efficient indexing techniques are available to reduce the computation needed to find the nearest neighbors of a test instance.\n",
    "<space>\n",
    "<img src=\"knn-Algo.png\">\n",
    "<space>\n",
    "Once the nearest neighbor list is obtained, the test instance is classified based on the majority class of its nearest neighbors:\n",
    "\n",
    "$$\n",
    "Majority \\hspace{0.5cm} Voting : y' = \\underset{v}{argmax} \\sum_{(x_i, y_i)\\in D_z} I(v=y_i)\n",
    "$$\n",
    "\n",
    "where $v$ is a class label, $yi$ is the class label for one of the nearest neighbors, and $I(·)$ is an indicator function that returns the value 1 if its argument is true and 0 otherwise.\n",
    "\n",
    "In the majority voting approach, every neighbor has the same impact on the classification. This makes the algorithm sensitive to the choice of $k$, as shown in figure. One way to reduce the impact of $k$ is to weight the influence of each nearest neighbor $xi$ according to its distance: \n",
    "\n",
    "$$wi = \\frac{1}{d(x′,xi)^2} $$ \n",
    "\n",
    "As a result, training examples that are located far away from *z* have a weaker impact on the classification compared to those that are located close to *z*. Using the distance-weighted voting scheme, the class label can be determined as follows:\n",
    "\n",
    "$$\n",
    "Distance-Weighted \\hspace{0.5cm} Voting : y' = \\underset{v}{argmax} \\sum_{(x_i, y_i)\\in D_z} w_i * I(v=y_i)\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a79321ab717100f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-26T11:19:43.365103Z",
     "start_time": "2023-12-26T11:19:43.328499Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
